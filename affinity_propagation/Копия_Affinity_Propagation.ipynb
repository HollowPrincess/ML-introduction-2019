{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия Affinity Propagation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "c6MEOHGE2CLw",
        "Kf2hs3j-5nN_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooz1sVP0ZoRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import os.path\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtAHPwyXCkXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6MEOHGE2CLw",
        "colab_type": "text"
      },
      "source": [
        "# Affinity Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AwH0VBffZky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_R(A, S, old_R, diagonal_idx_start, from_user_edges_idxs, lam):\n",
        "    mat_sum = np.add(A, S)\n",
        "    R = old_R.copy()\n",
        "\n",
        "    for rows_with_user in from_user_edges_idxs:\n",
        "        max_in_row_idx = np.argmax(mat_sum[rows_with_user]) # get idx of max value in row in A+S\n",
        "\n",
        "        R[rows_with_user] = np.subtract(S[rows_with_user], mat_sum[rows_with_user[max_in_row_idx]])\n",
        "        \n",
        "        rows_with_user_without_max = rows_with_user.copy()\n",
        "        rows_with_user_without_max = np.delete(arr = rows_with_user_without_max, obj = max_in_row_idx)\n",
        "        try:\n",
        "            second_max_in_row_value = np.max(mat_sum[rows_with_user_without_max]) # get idx of second max value in row in A+S if it exists\n",
        "        except:   #if there is only one value in this row:\n",
        "            second_max_in_row_value = -np.inf\n",
        "\n",
        "        R[rows_with_user[max_in_row_idx]] = np.subtract(S[rows_with_user[max_in_row_idx]], second_max_in_row_value) # if j==k\n",
        "    return old_R*lam+(1-lam)*R"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtTHrSzXIl3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_A(R, A, to_user_edges_idxs, diagonal_idx_start, lam):\n",
        "    R_non_neg = R.copy()\n",
        "    R_non_neg[R_non_neg < 0] = 0\n",
        "\n",
        "    A_old = A.copy()\n",
        "\n",
        "    for user, edges_idxs in zip(users, to_user_edges_idxs):\n",
        "        sum_non_neg = np.subtract(np.sum(R_non_neg[edges_idxs]), R_non_neg[diagonal_idx_start:][user])   # sum(max(0, r(j,k))) - max(0, r(i,i))\n",
        "\n",
        "        A_slice = np.add(np.subtract(sum_non_neg, R_non_neg[edges_idxs]), R[diagonal_idx_start:][user]) # sum_non_neg - max(0, r(k,k)) + r(k,k)\n",
        "        A_slice[A_slice > 0] = 0 # min(0, A)\n",
        "\n",
        "        A[edges_idxs] = A_slice #A row\n",
        "        A[diagonal_idx_start:][user] = sum_non_neg #A diag elem in row\n",
        "        \n",
        "    return A_old*lam+(1-lam)*A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecbMvl7aTgEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def affinity_propagation(S, edges, from_user_edges_idxs, to_user_edges_idxs, diagonal_idx_start, iter_num, lam):\n",
        "    R = np.array([0]*len(S), dtype=float)\n",
        "    A = R.copy()\n",
        "\n",
        "    for i in range(iter_num):\n",
        "        R=update_R(A, S, R, diagonal_idx_start, from_user_edges_idxs, lam)\n",
        "        A=update_A(R, A, to_user_edges_idxs, diagonal_idx_start, lam)\n",
        "\n",
        "    for_exm = np.add(A, R)\n",
        "    exm=np.array([])\n",
        "    for user, from_edges in zip(users, from_user_edges_idxs):\n",
        "        exm = np.append(arr = exm, values = edges[from_edges[np.argmax(for_exm[from_edges])]][1])\n",
        "\n",
        "    for user in range(len(exm)): # drop transactions\n",
        "        if user != exm[user]:\n",
        "            exm[exm == user] = exm[user]\n",
        "    return exm, R, A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf2hs3j-5nN_",
        "colab_type": "text"
      },
      "source": [
        "# Cluster Data Upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjFIqccm7vqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data_files\n",
        "os.chdir('/content/data_files')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syf1svCufGjC",
        "colab_type": "code",
        "outputId": "7ba93674-2f50-4a65-ea71-35a178591af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# https://drive.google.com/file/d/1XmXZT1OxZI4UwomSQs6AeqJ5QpkcjQ9I/view?usp=sharing\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1XmXZT1OxZI4UwomSQs6AeqJ5QpkcjQ9I',\n",
        "                                    dest_path='/content/data_files/friends_graph.txt.gz',\n",
        "                                    unzip=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1XmXZT1OxZI4UwomSQs6AeqJ5QpkcjQ9I into /content/data_files/friends_graph.txt.gz... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfJ812-u-taf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges=np.loadtxt(\"/content/data_files/friends_graph.txt.gz\", delimiter=\"\t\",dtype=int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh8YfhBw5jWS",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvTgnnhj8bNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users = np.unique(edges)\n",
        "part_size=len(edges)\n",
        "diagonal_idx_start = part_size*2\n",
        "\n",
        "edges=np.concatenate([edges, edges[:,[-1,-2]], np.vstack([users, users]).T])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7EcSvPdmlJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sorted_users = np.sort(users.copy())\n",
        "#print((sorted_users == users).all()) True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uu0FR80J8IZv",
        "colab": {}
      },
      "source": [
        "from_user_edges_idxs=[]\n",
        "to_user_edges_idxs=[]\n",
        "\n",
        "for user in users:\n",
        "    from_idxs = np.argwhere(edges[:, 0]==user)[:,0] # i -> j\n",
        "    from_user_edges_idxs.append(from_idxs) \n",
        "    to_idxs = np.argwhere(edges[:, 1]==user)[:,0]\n",
        "    to_user_edges_idxs.append(to_idxs) # j -> i\n",
        "\n",
        "from_user_edges_idxs = np.asarray(from_user_edges_idxs)\n",
        "to_user_edges_idxs = np.asarray(to_user_edges_idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABJUx2DNQqso",
        "colab_type": "text"
      },
      "source": [
        "# Run clusterization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9GEPJFE8LaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iter_num = 100\n",
        "lam = 0.9\n",
        "\n",
        "S = np.concatenate([np.random.rand(diagonal_idx_start)+1, np.array([-1.5] * len(users), dtype=float)])\n",
        "clusters, R, A = affinity_propagation(S, edges, from_user_edges_idxs, to_user_edges_idxs, diagonal_idx_start, iter_num, lam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdpxNeti8kG9",
        "colab_type": "code",
        "outputId": "fc4dcbc3-d030-4736-befc-83a9ff8b7ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(np.unique(clusters))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbDTPMOuCBx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.savetxt('clusters.txt', clusters, delimiter=',') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct0p5oQBQuuW",
        "colab_type": "text"
      },
      "source": [
        "# Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeXhCLyjRX6v",
        "colab_type": "text"
      },
      "source": [
        "## Data Upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn9I8F_6fKsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data_files\n",
        "os.chdir('/content/data_files')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "525es3auRVfv",
        "colab_type": "code",
        "outputId": "ba98b3f3-390b-42fb-8576-c0101a7a9704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://drive.google.com/file/d/1haAf1soInsAaW_kYiqB6RFqqmnXhaVT9/view?usp=sharing\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1haAf1soInsAaW_kYiqB6RFqqmnXhaVT9',\n",
        "                                    dest_path='/content/data_files/checkins.txt.gz',\n",
        "                                    unzip=False)\n",
        "\n",
        "checkins = pd.read_csv(\"/content/data_files/checkins.txt.gz\", sep=\"\t\", header=None).drop_duplicates()[[0, 4]]\n",
        "checkins.columns = [\"user_id\", \"location_id\"]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1haAf1soInsAaW_kYiqB6RFqqmnXhaVT9 into /content/data_files/checkins.txt.gz... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7qs-J2ncxH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clusters = np.loadtxt(\"/content/data_files/clusters.txt\", delimiter=\",\", dtype=float)\n",
        "clusters = clusters.astype(int)\n",
        "clusters_df = pd.DataFrame(clusters)\n",
        "clusters_df = clusters_df.reset_index()\n",
        "clusters_df.columns = [\"user_id\", \"cluster_id\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGpEjZF-NBKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.merge(checkins, clusters_df, on=['user_id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0krIYCAFWbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c26939ec-4ce9-405b-f870-77295a9d76bc"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>location_id</th>\n",
              "      <th>cluster_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>22847</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>420315</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>316637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>16516</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>5535878</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  location_id  cluster_id\n",
              "0        0        22847           0\n",
              "1        0       420315           0\n",
              "2        0       316637           0\n",
              "3        0        16516           0\n",
              "4        0      5535878           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkrFXOf4RdNM",
        "colab_type": "text"
      },
      "source": [
        "## Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyNaTuoAUB9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def for_recall_at_k(data, ans, k = 10):\n",
        "    try:\n",
        "        data = set(data[:k])\n",
        "    except:\n",
        "        data = set(data)\n",
        "    ans = set(ans)\n",
        "    return len(data.intersection(ans))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn0rc5dhoKUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users = np.unique(df.user_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxXNSJO_oFKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(users, test_size=0.1, shuffle=True)\n",
        "#train, test = train_test_split(users, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HqCfVoHo7P4",
        "colab_type": "code",
        "outputId": "3d9f910c-c6fe-4911-9c35-3c3a4ba98c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_checkins = df.loc[df.user_id.isin(train)]\n",
        "test_checkins = df.loc[df.user_id.isin(test)]\n",
        "\n",
        "top10_locations = np.array(train_checkins.groupby(by='location_id')['location_id'].count().sort_values(ascending = False).iloc[:10].index)\n",
        "train_loc_ratings = train_checkins.groupby(by = [\"cluster_id\", \"location_id\"])[\"location_id\"].count()\n",
        "train_loc_ratings = train_loc_ratings.reset_index(name='rating').sort_values(by = [\"cluster_id\", \"rating\"], ascending = False)\n",
        "\n",
        "cluster_score = 0\n",
        "baseline_score = 0\n",
        "\n",
        "amount_counter = 10 * len(test)\n",
        "\n",
        "for user in test:\n",
        "    cluster = clusters[user]\n",
        "    user_locations = test_checkins.loc[test_checkins.user_id == user, \"location_id\"].values\n",
        "\n",
        "    if (cluster in train_loc_ratings.cluster_id): #if we have info for this cluster      \n",
        "        cluster_top_loc = train_loc_ratings.loc[train_loc_ratings.cluster_id == cluster, \"location_id\"].values        \n",
        "        cluster_score += for_recall_at_k(cluster_top_loc, user_locations)\n",
        "    else:\n",
        "        cluster_score += for_recall_at_k(top10_locations, user_locations)\n",
        "\n",
        "    baseline_score += for_recall_at_k(top10_locations, user_locations)\n",
        "\n",
        "cluster_score /= amount_counter\n",
        "baseline_score /= amount_counter\n",
        "\n",
        "print(\"BASELINE: \", baseline_score)\n",
        "print(\"CLUSTER RECOMMENDATION: \", cluster_score)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BASELINE:  0.016330532212885156\n",
            "CLUSTER RECOMMENDATION:  0.04071895424836601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgiY0s3IS5D6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}