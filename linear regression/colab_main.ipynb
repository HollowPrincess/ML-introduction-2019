{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML LinReg",
      "provenance": [],
      "collapsed_sections": [
        "0cLj0WQcADuI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cLj0WQcADuI",
        "colab_type": "text"
      },
      "source": [
        "# Data upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COWbkB5lU3a6",
        "colab_type": "code",
        "outputId": "83c71924-a263-42f1-c849-adc5df969552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "\n",
        "#!pip install googledrivedownloader\n",
        "!mkdir data_files\n",
        "\n",
        "import os.path\n",
        "os.chdir('/content/data_files')\n",
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1Vy6G1IFiWdTGoHo7YaNVYw7v9Xw3XnuT',\n",
        "                                    dest_path='/content/data_files/Features_Variant_1.zip',\n",
        "                                    unzip=True)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1Vy6G1IFiWdTGoHo7YaNVYw7v9Xw3XnuT into /content/data_files/Features_Variant_1.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DWEBnHzAMco",
        "colab_type": "text"
      },
      "source": [
        "# DataFrame Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfEWZzleYDnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "data=pd.read_csv('/content/data_files/Features_Variant_1.csv', header=None).drop_duplicates()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnmU0-DWYNwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get and fit features names\n",
        "features_names=np.array(['page_likes_num',#1\n",
        "               'page_checkins',#2\n",
        "               'page_talking_about',#3\n",
        "                'page_cat',#4\n",
        "                'page_statistics',#5-29 #mean, avg etc.\n",
        "                'comments_num_before_base_time',#30\n",
        "                'comments_num_in_last_24_hours',#31 #last day\n",
        "                'comments_num_in_last_48_to_24_hours',#32 #day before last\n",
        "                'comments_num_in_first_24_hours',#33\n",
        "                'comments_difference_in_last_two_days', #34 (32-31)\n",
        "                'base_time', #35\n",
        "                'character_num_in_post', #36\n",
        "                'share_num',#37\n",
        "                'post_promotion', #38 binary\n",
        "                'h_local', #39 This describes the H hrs, for which we have the target variable/ comments received. \n",
        "                'post_published_weekday', #40-46 This represents the day(Sunday...Saturday) on which the post was published. \n",
        "                'base_ditetime_weekday', #47-53 This represents the day(Sunday...Saturday) on selected base Date/Time. \n",
        "                'target' #54 The no of comments in next H hrs(H is given in Feature no 39).                \n",
        "               ])\n",
        "\n",
        "for index in range(5,29):\n",
        "    features_names=np.insert(features_names, index, features_names[4]+'_'+str(index-4))\n",
        "    \n",
        "weekday=('sunday', 'monday','tuesday', 'wednesday', 'thursday', 'friday', 'saturday')    \n",
        "\n",
        "for index in range(40,47):\n",
        "    features_names=np.insert(features_names,index, features_names[39]+'_'+ weekday[index-40])\n",
        "features_names=np.delete(features_names, 39)\n",
        "\n",
        "for index in range(47,54):\n",
        "    features_names=np.insert(features_names,index, features_names[46]+'_'+ weekday[index-47])\n",
        "features_names=np.delete(features_names, 46)\n",
        "\n",
        "data.columns=features_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFri2mdN78ri",
        "colab_type": "code",
        "outputId": "380d5ed7-3d95-42fd-d8a9-54c3f9c2e765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "y=data.nunique(axis=0).sort_values()\n",
        "print(y.head())\n",
        "data=data.drop(columns=['post_promotion']) #post promotion has only zero values we can drop this col because it isn't informative"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "post_promotion                      1\n",
            "post_published_weekday_sunday       2\n",
            "post_published_weekday_monday       2\n",
            "post_published_weekday_tuesday      2\n",
            "post_published_weekday_wednesday    2\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SphoM5_38Cyy",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsJt31hB7_6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#'page_cat' to dummy because it is a category\n",
        "data=pd.concat([data,pd.get_dummies(data['page_cat'], prefix='page_cat')], axis=1)\n",
        "data=data.drop(columns=['page_cat'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFU5gRgQ8GpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data shuffling\n",
        "from sklearn.utils import shuffle\n",
        "data=shuffle(data).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0qvySLo8Irk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(df):\n",
        "    std=np.std(df, ddof=1).replace(0, 1)\n",
        "    mean=np.mean(df)\n",
        "    return (df-mean)/std, mean, std\n",
        "\n",
        "def normalize_with_params(df, mean, std):\n",
        "    return (df-mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USv03zuk8K9B",
        "colab_type": "text"
      },
      "source": [
        "# learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OH3HuGA8NDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_RMSE(target, pred, gamma, w):\n",
        "    return np.sqrt(\n",
        "        np.sum((target-pred)**2)/len(pred)+gamma*np.linalg.norm(w)\n",
        "    )\n",
        "\n",
        "def get_para_w(old_w, df, pred, lam, gamma, indices):\n",
        "    #indices=np.random.choice(df.shape[0]-1,terms_num,replace=False)\n",
        "    old_w=old_w+2*lam*(\n",
        "          (np.dot((df.loc[indices,'target']-pred[indices]).values,df.iloc[indices,:-1].values))/len(pred)\n",
        "        )\n",
        "    return old_w\n",
        "\n",
        "def get_para_w0(old_w0, df, pred, lam, gamma, indices):\n",
        "    return old_w0+2*lam*(\n",
        "        (np.sum(df.loc[indices,'target']-pred[indices]))/len(pred))\n",
        "\n",
        "def get_prediction(w,w0,x_df):\n",
        "    return np.dot(x_df, w)+w0\n",
        "    \n",
        "def gradient_descend(df, lam, gamma, terms_num, max_iter):\n",
        "    df=df.reset_index(drop=True)\n",
        "    w=np.array([0]*(df.shape[1]-1), dtype=float) #one column is the target\n",
        "    w0=0.0\n",
        "    prediction=get_prediction(w,w0,df.iloc[:,:-1])\n",
        "    minRMSE=custom_RMSE(df['target'], prediction, gamma, w)\n",
        "\n",
        "    best_params=np.append(w,w0)\n",
        "    best_pred=prediction\n",
        "\n",
        "    curr_err=10\n",
        "    err=1e-4\n",
        "    \n",
        "    iter_num=0\n",
        "    while (curr_err>err) & (iter_num<max_iter) :    \n",
        "        iter_num+=1\n",
        "        df=shuffle(df)\n",
        "        prediction=get_prediction(w,w0,df.iloc[:,:-1])\n",
        "        curr_err=prediction.copy()\n",
        "        \n",
        "        for batch_counter in range(0, math.ceil(df.shape[0]/terms_num)):\n",
        "            indices=np.array(df.iloc[batch_counter*terms_num:(batch_counter+1)*terms_num].index)            \n",
        "            w=get_para_w(w, df, prediction, lam, gamma, indices)\n",
        "            w0=get_para_w0(w0, df, prediction, lam, gamma, indices)            \n",
        "            prediction=get_prediction(w,w0,df.iloc[:,:-1])\n",
        "\n",
        "            if custom_RMSE(df['target'], prediction, gamma, w)<minRMSE:\n",
        "                minRMSE=custom_RMSE(df['target'], prediction, gamma, w)\n",
        "                best_params=np.append(w,w0)\n",
        "                best_pred=prediction\n",
        "        curr_err=np.linalg.norm(curr_err-prediction)\n",
        "            \n",
        "    print('Iterations number is:' +str(iter_num))\n",
        "    if iter_num==max_iter:\n",
        "        print('The maximum number of iterations was reached.')\n",
        "    print('RMSE is:'+str(minRMSE))\n",
        "    print('R2 is:'+str(custom_R2(df.iloc[:,-1], best_pred)))\n",
        "    \n",
        "    return best_params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSoB3O_p8P4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set algo params:\n",
        "lam=5e-4\n",
        "gamma=0 #now we needn't it\n",
        "terms_num=100\n",
        "max_iter=50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KFC7qG88SM0",
        "colab_type": "text"
      },
      "source": [
        "# cross-val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-QKQ5Ii8UUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_R2(target, pred):\n",
        "    return 1-(np.sum((target-pred)**2))/(np.sum((target-np.mean(target))**2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La_QVxrZ8Wgf",
        "colab_type": "code",
        "outputId": "b4e6d3fc-d209-4bf6-874b-42358e0c1bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "res=pd.DataFrame()\n",
        "\n",
        "parts=range(1,6)\n",
        "idxs=[round(data.shape[0]/5)*(i-1) for i in range(1,6)]\n",
        "idxs.append(data.shape[0])\n",
        "\n",
        "for part in parts:\n",
        "    #separate dataset\n",
        "    test_part=data[idxs[part-1]:idxs[part]]\n",
        "    train_part=data.drop(data.index[idxs[part-1]:idxs[part]])\n",
        "    #features normalization (xi-mean)/std_err:\n",
        "    train_part.iloc[:,:-1], mean, std=normalize(train_part.iloc[:,:-1])#fit and transform train\n",
        "    test_part.iloc[:,:-1]=normalize_with_params(test_part.iloc[:,:-1], mean, std) #transform test\n",
        "    params=gradient_descend(train_part, lam, gamma, terms_num, max_iter) #model    \n",
        "    test_pred=get_prediction(params[:-1],params[-1],test_part.iloc[:,:-1])\n",
        "    RMSE=custom_RMSE(test_part['target'], test_pred, gamma, params[:-1])\n",
        "    r2=custom_R2(test_part['target'], test_pred)\n",
        "    params=np.insert(params, 0 , [RMSE,r2])\n",
        "    res[part]=params"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iterations number is:50\n",
            "The maximum number of iterations was reached.\n",
            "RMSE is:0.9997339912519347\n",
            "R2 is:-0.0016002975011735199\n",
            "Iterations number is:50\n",
            "The maximum number of iterations was reached.\n",
            "RMSE is:0.9999179514598752\n",
            "R2 is:-0.0014085880997212197\n",
            "Iterations number is:50\n",
            "The maximum number of iterations was reached.\n",
            "RMSE is:0.9998938493347957\n",
            "R2 is:-0.0017133504058663984\n",
            "Iterations number is:50\n",
            "The maximum number of iterations was reached.\n",
            "RMSE is:0.9998363876055629\n",
            "R2 is:-0.0018796021080604852\n",
            "Iterations number is:50\n",
            "The maximum number of iterations was reached.\n",
            "RMSE is:0.9998726994413694\n",
            "R2 is:-0.0015583151967220044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4xADw9j8Yc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_idxs=np.array(['w'+str(i) for i in range(1,res.shape[0]-2)])\n",
        "text_idxs=np.append(text_idxs,'w0')\n",
        "text_idxs=np.insert(text_idxs, 0, ['RMSE', 'r2'])\n",
        "res.index=text_idxs\n",
        "\n",
        "res['mean']=np.mean(res, axis=1)\n",
        "res['std']=np.std(res.iloc[:,:-1], ddof=1, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF7tslOl8amn",
        "colab_type": "code",
        "outputId": "c8aa1eb6-dc3d-430e-ca17-1ac935ebf0e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "res.iloc[:2]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RMSE</th>\n",
              "      <td>1.227466</td>\n",
              "      <td>1.021992</td>\n",
              "      <td>0.897118</td>\n",
              "      <td>1.039163</td>\n",
              "      <td>0.793094</td>\n",
              "      <td>0.995766</td>\n",
              "      <td>0.163603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r2</th>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.000353</td>\n",
              "      <td>0.000737</td>\n",
              "      <td>0.025681</td>\n",
              "      <td>0.005410</td>\n",
              "      <td>0.011335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             1         2         3         4         5      mean       std\n",
              "RMSE  1.227466  1.021992  0.897118  1.039163  0.793094  0.995766  0.163603\n",
              "r2    0.000167  0.000111  0.000353  0.000737  0.025681  0.005410  0.011335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}